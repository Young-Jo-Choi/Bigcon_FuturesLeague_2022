{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import gzip\n",
    "from IPython.display import display\n",
    "\n",
    "data = ['../BigContest_data/' + file for file in os.listdir('../BigContest_data')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_spec = pd.read_csv(data[0])\n",
    "log_data = pd.read_csv(data[1])\n",
    "loan_result = pd.read_csv(data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_spec = pd.read_csv('../processed/user_spec_complete_except4.csv')\n",
    "with gzip.open('../processed/user_spec_filled.pickle', 'rb') as f:\n",
    "    user_spec_filled = pickle.load(f)\n",
    "with gzip.open('../processed/all_info.pickle', 'rb') as f:\n",
    "    all_info = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_result_train = pd.read_csv('../processed/loan_result_train.csv')\n",
    "loan_result_test = pd.read_csv('../processed/loan_result_test.csv')\n",
    "concat_log = pd.read_csv('../processed/concat_log_complete2.csv')\n",
    "pattern_binary = pd.read_csv('../processed/pattern_binary.csv')\n",
    "# user_spec = pd.read_csv('../processed/user_spec_complete_except4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_comma(x):\n",
    "    x_str = str(int(x))\n",
    "    first_comma = len(x_str)%3\n",
    "    if first_comma==0:\n",
    "        comma_str = ''\n",
    "    else:\n",
    "        comma_str = x_str[:first_comma] + ','\n",
    "    remain_str = x_str[first_comma:]\n",
    "    while len(remain_str)>=3:\n",
    "        comma_str += remain_str[:3]+','\n",
    "        remain_str = remain_str[3:]\n",
    "    return comma_str[:-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# log data에 대한 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_log['event'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_actions = ['UseLoanManage','CompleteIDCertification','UsePrepayCalc','UseDSRCalc','GetCreditInfo','is_applied_Y']\n",
    "cond = concat_log['event'].isin(valid_actions)\n",
    "concat_log_cond = concat_log[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts(x,extra_indexes,order,normalize=True):\n",
    "    value_counted = pd.Series(x).value_counts(normalize=normalize)\n",
    "    for extra_index in extra_indexes:\n",
    "        if extra_index not in value_counted.index:\n",
    "            value_counted[extra_index] = 0\n",
    "    value_counted = value_counted.sort_index()\n",
    "    value_counted.index = value_counted.index +'_' + order\n",
    "    return value_counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_count(df):\n",
    "    is_applied_Y_index = np.where(df['event']=='is_applied_Y')[0]\n",
    "    if len(is_applied_Y_index)>=2:\n",
    "        first = is_applied_Y_index[0]\n",
    "        last = is_applied_Y_index[-1]\n",
    "        first_action = value_counts(df['event'].values[:first],valid_actions,'first')\n",
    "        last_action = value_counts(df['event'].values[first:last],valid_actions,'last')\n",
    "    elif len(is_applied_Y_index)==1:\n",
    "        first = is_applied_Y_index[0]\n",
    "        first_action = value_counts(df['event'].values[:first],valid_actions,'first')\n",
    "        last_action = pd.Series([0]*len(valid_actions), index=valid_actions).sort_index()\n",
    "        last_action.index = last_action.index +'_last'\n",
    "    else:\n",
    "        first_action = pd.Series([0]*len(valid_actions), index=valid_actions).sort_index()\n",
    "        last_action = pd.Series([0]*len(valid_actions), index=valid_actions).sort_index()\n",
    "        first_action.index = first_action.index +'_first'\n",
    "        last_action.index = last_action.index +'_last'\n",
    "    actions_freq = first_action.append(last_action)\n",
    "    return actions_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.51589287916819 분\n"
     ]
    }
   ],
   "source": [
    "# 주의 : 30분(?) 가량 걸림\n",
    "import time\n",
    "start = time.time()\n",
    "freq_action = concat_log_cond.groupby('user_id').apply(freq_count)\n",
    "print((time.time() - start)/60,'분')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_action.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "with gzip.open('../processed/freq_action.pickle','wb') as f:\n",
    "    pickle.dump(freq_action, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../processed/freq_action.pickle','rb') as f:\n",
    "    freq_action = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# user_spec과의 합치는 방안 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_columns = ['credit_score', 'yearly_income','income_type', 'employment_type', 'houseown_type',\n",
    "'company_enter_month','personal_rehabilitation_yn', 'personal_rehabilitation_complete_yn']\n",
    "user_spec[filled_columns] = user_spec_filled[filled_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_spec에는 있으나 log_data 순서 feature에는 없는 user_id\n",
    "# 해당 행들은 결측치로 채워질 것임\n",
    "len(np.setdiff1d(user_spec['user_id'],freq_action.index.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_data 순서 feature에는 있으나 user_spec에는 없는 user_id\n",
    "len(np.setdiff1d(freq_action.index.tolist(),user_spec['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_comma(user_spec.shape[0]), split_comma(all_info.shape[0]), split_comma(loan_result.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_info['user_id'] = user_spec['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_info = pd.merge(all_info, freq_action, left_on='user_id', right_index=True, how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# is_applied 종속변수로 추가\n",
    "- 6월 날짜는 빼는 과정 거칠 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_result_train.query('is_applied==1').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음과 같이 application_id가 1이 포함돼 있으면 일단 all_info에 1로 추가\n",
    "# bank_id, product_id, loan_limit, loan_rate 역시 고려대상이지만 application_id 하나당 다음 여러 행을 포함하도록 병합하면 데이터사이즈가 너무 커질 것 -> 학습 시간이 어마어마할듯\n",
    "# 하나의 is_applied만 포함한 데이터로 feature selection 후 bank_id, product_id, loan_limit, loan_rate 고려하는 방식이 어떨지\n",
    "loan_result_train.query('application_id == 1369315')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아직 6월의 NaN은 고려하지 않음\n",
    "# 0과 6월 데이터는 모두 nan으로 고려\n",
    "applied_application_id = loan_result_train.query('is_applied==1')['application_id'].unique()\n",
    "all_info_is_applied = all_info['application_id'].map(lambda x:1 if x in applied_application_id else np.nan)\n",
    "all_info['is_applied'] = all_info_is_applied"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 속성과 범주별 대표값 속성 concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_spec.shape, all_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_spec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입사년차 월 단위로 추가해주기\n",
    "enter_period_year = pd.to_datetime(user_spec['insert_time']).dt.year - pd.to_datetime(user_spec['company_enter_month']).dt.year\n",
    "enter_period_year *= 12\n",
    "enter_period_month = pd.to_datetime(user_spec['insert_time']).dt.month - pd.to_datetime(user_spec['company_enter_month']).dt.month\n",
    "enter_period = enter_period_year+enter_period_month\n",
    "enter_period /= 12\n",
    "enter_age = pd.to_datetime(user_spec['company_enter_month']).dt.year - user_spec['birth_year'].fillna(2022) + 1\n",
    "enter_period[enter_age <= 15] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나이변수 추가해주기\n",
    "age = pd.to_datetime(user_spec['insert_time']).dt.year - user_spec['birth_year'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_spec['company_period_month'] = enter_period\n",
    "user_spec['age'] = age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_att = pd.concat([user_spec.reset_index(drop=True), all_info.drop('application_id',axis=1).reset_index(drop=True)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xpython",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
